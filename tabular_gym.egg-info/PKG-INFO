Metadata-Version: 2.4
Name: tabular-gym
Version: 0.1.0
Summary: A tabular reinforcement learning gym for constrained MDPs and inverse reinforcement learning
Author-email: Andreas Schlaginhaufen <andreas.schlaginhaufen@epfl.ch>
License: MIT License
        
        Copyright (c) 2023 andrschl
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
        
Project-URL: Homepage, https://github.com/username/tabular-gym
Project-URL: Repository, https://github.com/username/tabular-gym
Project-URL: Documentation, https://github.com/username/tabular-gym
Project-URL: Bug Tracker, https://github.com/username/tabular-gym/issues
Keywords: reinforcement learning,inverse reinforcement learning,constrained mdp,tabular
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.20.0
Requires-Dist: scipy>=1.7.0
Requires-Dist: einops>=0.3.0
Requires-Dist: matplotlib>=3.3.0
Requires-Dist: plotly>=5.0.0
Requires-Dist: wandb>=0.12.0
Requires-Dist: sigpy>=0.1.0
Requires-Dist: pandas>=1.3.0
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: black>=21.0; extra == "dev"
Requires-Dist: flake8>=3.8; extra == "dev"
Dynamic: license-file

# Tabular Gym

[**Installation**](#installation) |
[**Quick Start**](#quick-start) |
[**Examples**](#examples) |
[**Contributing**](#contributing)

A tabular reinforcement learning gym for constrained MDPs and inverse reinforcement learning. This package implements the experiments of the paper [Towards the Transferability of Rewards Recovered via Regularized Inverse Reinforcement Learning](https://proceedings.neurips.cc/paper_files/paper/2024/hash/2628d4d3b054c2d7ad33ab03435204f4-Abstract-Conference.html).

## Installation

```bash
git clone <repository-url>
cd tabular_gym
pip install -e .
```

## Quick Start

```python
import numpy as np
from tabular_gym import Gridworld, WindyGridworld
from tabular_gym.algs import irl_gda, empirical_expert_feature_expectation

# Create a gridworld environment
env = Gridworld(grid_width=5, grid_height=5, noise=0.1, gamma=0.9)

# Create a windy gridworld for transfer experiments
windy_env = WindyGridworld(grid_width=5, grid_height=5, wind_level=0.5, gamma=0.9)

# Run inverse reinforcement learning
# ... (see examples for full usage)
```

## Examples

The `experiments/` directory contains example scripts that demonstrate how to use the package:

- To generate synthetic expert data run `experiments/run_get_windy_experts.sh`
- To run IRL run `experiments/run_multi_expert_irl.sh`
- To evaluate the transferability run `experiments/run_check_transferability.sh`
- For generating the plot run `experiments/plotting.py`
- The computations for Example 3.2 are done in the notebook `experiments/example.ipynb`


## Contributing
If you would like to contribute to the project please reach out to [Andreas Schlaginhaufen](mailto:andreas.schlaginhaufen@epfl.ch?subject=[transfer_irl]%20Contribution%20to%20transfer_irl). If you found this library useful in your research, please consider citing the following paper:
```
@inproceedings{NEURIPS2024_2628d4d3,
 author = {Schlaginhaufen, Andreas and Kamgarpour, Maryam},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {A. Globerson and L. Mackey and D. Belgrave and A. Fan and U. Paquet and J. Tomczak and C. Zhang},
 pages = {21461--21501},
 publisher = {Curran Associates, Inc.},
 title = {Towards the Transferability of Rewards Recovered via Regularized Inverse Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2024/file/2628d4d3b054c2d7ad33ab03435204f4-Paper-Conference.pdf},
 volume = {37},
 year = {2024}
}
```
